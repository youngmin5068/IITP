{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from timm.models.layers import DropPath, trunc_normal_\n",
    "class DWConv(nn.Module):\n",
    "    def __init__(self, dim=768):\n",
    "        super(DWConv, self).__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, 3, 1, 1, bias=True, groups=dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dwconv(x)\n",
    "        return x\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Conv2d(in_features, hidden_features, 1)\n",
    "        self.dwconv = DWConv(hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Conv2d(hidden_features, out_features, 1)\n",
    "        self.drop = nn.Dropout(drop)\n",
    " \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dwconv(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LKA(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv0 = nn.Conv2d(dim, dim, 5, padding=2, groups=dim)\n",
    "        self.conv_spatial = nn.Conv2d(dim, dim, 7, stride=1, padding=9, groups=dim, dilation=3)\n",
    "        self.conv1 = nn.Conv2d(dim, dim, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.clone()        \n",
    "        attn = self.conv0(x)\n",
    "        attn = self.conv_spatial(attn)\n",
    "        attn = self.conv1(attn)\n",
    "\n",
    "        return u * attn\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim,ratio=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.proj_1 = nn.Conv2d(dim, dim//ratio, 1)\n",
    "        self.activation = nn.GELU()\n",
    "        self.spatial_gating_unit = LKA(dim//ratio)\n",
    "        self.proj_2 = nn.Conv2d(dim//ratio, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shorcut = x.clone()\n",
    "        x = self.proj_1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.spatial_gating_unit(x)\n",
    "        x = self.proj_2(x)\n",
    "        x = x + shorcut\n",
    "        return x\n",
    "\n",
    "\n",
    "class LKA_Block(nn.Module):\n",
    "    def __init__(self, in_channel,out_channel, mlp_ratio=4., drop=0.,drop_path=0., act_layer=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(out_channel,out_channel,3,padding=1),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.PReLU()               \n",
    "            )\n",
    "\n",
    "        self.attn = Attention(out_channel)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "        self.norm2 = nn.BatchNorm2d(out_channel)\n",
    "        mlp_hidden_dim = int(out_channel * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=out_channel, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "        layer_scale_init_value = 1e-2            \n",
    "        self.layer_scale_1 = nn.Parameter(\n",
    "            layer_scale_init_value * torch.ones((out_channel)), requires_grad=True)\n",
    "        self.layer_scale_2 = nn.Parameter(\n",
    "            layer_scale_init_value * torch.ones((out_channel)), requires_grad=True)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.double_conv(x)\n",
    "        x = x + self.drop_path(self.layer_scale_1.unsqueeze(-1).unsqueeze(-1) * self.attn(x))\n",
    "        x = x + self.drop_path(self.layer_scale_2.unsqueeze(-1).unsqueeze(-1) * self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "class PCA(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(PCA, self).__init__()\n",
    "        self.GAP = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # 서로 다른 커널 크기를 가진 1D 컨볼루션 레이어들\n",
    "        self.conv1d_1 = nn.Conv1d(input_channels, out_channels=input_channels, kernel_size=1)\n",
    "        self.conv1d_3 = nn.Conv1d(input_channels, out_channels=input_channels, kernel_size=3, padding=1)\n",
    "        self.conv1d_5 = nn.Conv1d(input_channels, out_channels=input_channels, kernel_size=5, padding=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        u = x.clone()\n",
    "        x = self.GAP(x)\n",
    "        x = x.squeeze(-1)  # 2D 형태로 변환\n",
    "\n",
    "        out1 = self.conv1d_1(x)\n",
    "        out3 = self.conv1d_3(x)\n",
    "        out5 = self.conv1d_5(x)\n",
    "\n",
    "        outs = out1 + out3 + out5\n",
    "        result = u * outs.unsqueeze(-1)\n",
    "\n",
    "        return result\n",
    "    \n",
    "\n",
    "class CA(nn.Module):\n",
    "    def __init__(self,dim,ratio=1):\n",
    "        super(CA, self).__init__()\n",
    "        self.avgpool_x = nn.AdaptiveAvgPool2d((1, None))  # X 축에 대한 pooling\n",
    "        self.avgpool_y = nn.AdaptiveAvgPool2d((None, 1))  # Y 축에 대한 pooling\n",
    "\n",
    "        self.conv = nn.Conv2d(dim,dim//ratio,1)\n",
    "        self.bn = nn.BatchNorm2d(dim//ratio)\n",
    "        self.siLU = nn.SiLU(inplace=True)\n",
    "\n",
    "        self.conv_1 = nn.Conv2d(dim//ratio,dim,1)\n",
    "        self.conv_2 = nn.Conv2d(dim//ratio,dim,1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.clone()\n",
    "        x_avg = self.avgpool_x(x)  # shape: (batch_size, 32, 1, 256)\n",
    "        y_avg = self.avgpool_y(x).permute(0,1,3,2)  # shape: (batch_size, 32, 1, 256)\n",
    "        # 두 결과를 높이 방향으로 연결\n",
    "        combined = torch.cat([x_avg, y_avg], dim=3).permute(0,1,3,2)  # shape: (batch_size, 32, 512, 1)\n",
    "\n",
    "        combined = self.siLU(self.bn(self.conv(combined)))\n",
    "        \n",
    "        split_1, split_2 = torch.split(combined, split_size_or_sections=combined.shape[2]//2, dim=2) \n",
    "        split_1 = self.sigmoid(self.conv_1(split_1)) # batch, 32, 256, 1\n",
    "        split_2 = self.sigmoid(self.conv_2(split_2.permute(0,1,3,2))) # batch, 32, 1, 256\n",
    "\n",
    "        result = u * split_1 * split_2\n",
    "        return result\n",
    "    \n",
    "class PCCA(nn.Module):\n",
    "    def __init__(self,dim):\n",
    "        super(PCCA, self).__init__()\n",
    "        self.PCA = PCA(dim)\n",
    "        self.CA = CA(dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        pca = self.PCA(x)\n",
    "        ca = self.CA(x)\n",
    "\n",
    "        return pca+ca\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class AP(nn.Module):\n",
    "    def __init__(self,in_channel,out_channel,first=False):\n",
    "        super(AP,self).__init__()\n",
    "\n",
    "        self.lka_block = LKA_Block(in_channel, out_channel)\n",
    "        self.pcca = PCCA(out_channel)\n",
    "        self.pool2d = nn.MaxPool2d(2)\n",
    "        self.first = first\n",
    "    def forward(self,x):\n",
    "        if not self.first:\n",
    "            x = self.pool2d(x)\n",
    "\n",
    "        x = self.lka_block(x)\n",
    "        x = self.pcca(x)\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(Upsample, self).__init__()\n",
    "        \n",
    "        # 전치 합성곱 (Transposed Convolution)\n",
    "        self.deconv = nn.ConvTranspose2d(in_channel, out_channel, kernel_size=2, stride=2)\n",
    "        self.ap = AP(in_channel,out_channel,first=True)\n",
    "        \n",
    "        # 활성화 함수\n",
    "        self.prelu = nn.PReLU()\n",
    "\n",
    "    def forward(self, x, skip_connection):\n",
    "\n",
    "        \n",
    "        # 전치 합성곱을 사용하여 업샘플링\n",
    "        x = self.deconv(x)\n",
    "        x = torch.cat([skip_connection, x], dim=1)\n",
    "        x = self.ap(x)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "\n",
    "class Out(nn.Module):\n",
    "    def __init__(self, in_channel, num_clases):\n",
    "        super(Out, self).__init__()\n",
    "        self.num_classes = num_clases\n",
    "\n",
    "        self.deconv = nn.ConvTranspose2d(in_channel, in_channel//2, kernel_size=2, stride=2)\n",
    "        self.ap = AP(in_channel,self.num_classes,first=True)\n",
    "        \n",
    "        # 활성화 함수\n",
    "        self.prelu = nn.PReLU()\n",
    "\n",
    "    def forward(self, x, skip_connection):\n",
    "\n",
    "        \n",
    "        # 전치 합성곱을 사용하여 업샘플링\n",
    "        x = self.deconv(x)\n",
    "        x = torch.cat([skip_connection, x], dim=1)\n",
    "        x = self.ap(x)\n",
    "    \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AP_UNet(nn.Module):\n",
    "    def __init__(self,in_channel,num_classes):\n",
    "        super(AP_UNet, self).__init__()\n",
    "        features = [32, 64, 128, 256, 512]\n",
    "        self.in_channel = in_channel\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.enc1 = AP(self.in_channel,features[0],first=True) # 32x512x512\n",
    "        self.enc2 = AP(features[0],features[1]) # 64x256x256\n",
    "        self.enc3 = AP(features[1],features[2]) # 128x128x128\n",
    "        self.enc4 = AP(features[2],features[3]) # 256x64x64\n",
    "        self.enc5 = AP(features[3],features[4]) # 512x32x32\n",
    "\n",
    "        self.up1 = Upsample(features[4],features[3])\n",
    "        self.up2 = Upsample(features[3],features[2])\n",
    "        self.up3 = Upsample(features[2],features[1])\n",
    "\n",
    "        self.out = Out(features[1],self.num_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x1 = self.enc1(x) \n",
    "        x2 = self.enc2(x1)\n",
    "        x3 = self.enc3(x2)\n",
    "        x4 = self.enc4(x3)\n",
    "        x5 = self.enc5(x4)\n",
    "        \n",
    "\n",
    "        x6 = self.up1(x5,x4)\n",
    "        x7 = self.up2(x6,x3)\n",
    "        x8 = self.up3(x7,x2)\n",
    "\n",
    "        out = self.out(x8,x1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 64, 64]) torch.Size([1, 128, 128, 128]) torch.Size([1, 64, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sample = torch.randn((1,1,512,512))\n",
    "\n",
    "ap_unet = AP_UNet(1,1)\n",
    "\n",
    "ap_unet(sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
